name: Enhanced Java Application Pipeline with Energy Monitoring

on:
  push:
    branches: [ pipeline-optimization ]
  pull_request:
    branches: [ pipeline-optimization ]

jobs:
  build-with-metrics:
    runs-on: ubuntu-latest
    timeout-minutes: 15

    steps:
      - uses: actions/checkout@v4

      - name: Setup Rust and Scaphandre
        run: |
          # Installer Rust si nécessaire
          if ! command -v cargo &> /dev/null; then
            curl https://sh.rustup.rs -sSf | sh -s -- -y
            source "$HOME/.cargo/env"
          fi

          # Installer Scaphandre et configurer les permissions
          cargo install scaphandre
          sudo setcap cap_sys_rawio=+ep $(which scaphandre)
          sudo chmod +r /dev/cpu/*/msr

      - name: Setup directories and install dependencies
        run: |
          set -eo pipefail
          
          # Créer la structure des répertoires
          mkdir -p metrics/system
          mkdir -p metrics/power
          mkdir -p metrics/performance
          
          # Installation des packages nécessaires
          sudo apt-get update
          sudo apt-get install -y \
            linux-tools-common \
            linux-tools-generic \
            python3-pip \
            python3-psutil \
            msr-tools

          # Charger le module msr
          sudo modprobe msr

          # Installer dépendances Python
          pip3 install pandas numpy

      - name: Create energy monitoring script
        run: |
          cat > energy_monitor.py << 'EOL'
          import subprocess
          import csv
          import os
          import sys
          import time
          import json
          import signal
          from datetime import datetime

          def monitor_energy(command, output_file):
              # Créer le répertoire si nécessaire
              os.makedirs(os.path.dirname(output_file), exist_ok=True)
          
              # Préparer le fichier CSV
              with open(output_file, 'w', newline='') as csvfile:
                  writer = csv.writer(csvfile)
                  writer.writerow(['Timestamp', 'Power_Watts', 'Component'])
          
              def signal_handler(signum, frame):
                  print("Signal reçu, arrêt du monitoring...")
                  sys.exit(0)
          
              signal.signal(signal.SIGTERM, signal_handler)
              signal.signal(signal.SIGINT, signal_handler)
          
              # Lancer la commande principale
              print(f"Exécution de la commande: {command}")
              main_process = subprocess.Popen(command, shell=True)
          
              try:
                  # Monitoring en continu pendant l'exécution de la commande
                  while main_process.poll() is None:
                      try:
                          # Exécuter scaphandre pour une seule mesure
                          scaphandre_output = subprocess.check_output(
                              ['sudo', 'scaphandre', 'json', '-n', '1'],
                              universal_newlines=True
                          )
          
                          # Traiter la mesure
                          process_measurement(scaphandre_output, output_file)
          
                          # Attendre 1 seconde avant la prochaine mesure
                          time.sleep(1)
          
                      except subprocess.CalledProcessError as e:
                          print(f"Erreur lors de la mesure: {e}")
                          continue
                      except Exception as e:
                          print(f"Erreur inattendue: {e}")
                          continue
          
                  return main_process.returncode
          
              finally:
                  if main_process.poll() is None:
                      main_process.terminate()
                      main_process.wait()

          def process_measurement(output, output_file):
              try:
                  data = json.loads(output.strip())
                  timestamp = data.get('timestamp', datetime.now().isoformat())
                  power = data.get('power', {}).get('total_power', 0)
          
                  with open(output_file, 'a', newline='') as csvfile:
                      writer = csv.writer(csvfile)
                      writer.writerow([timestamp, power, 'System'])
          
              except json.JSONDecodeError as e:
                  print(f"Erreur de décodage JSON: {e}")
              except Exception as e:
                  print(f"Erreur de traitement: {e}")

          def main():
              if len(sys.argv) < 3:
                  print("Usage: python energy_monitor.py 'command' output_file.csv")
                  sys.exit(1)
          
              command = sys.argv[1]
              output_file = sys.argv[2]
          
              try:
                  exit_code = monitor_energy(command, output_file)
                  sys.exit(exit_code)
              except Exception as e:
                  print(f"Erreur fatale: {e}")
                  sys.exit(1)

          if __name__ == '__main__':
              main()
          EOL
          
          chmod +x energy_monitor.py

      - name: Cache Maven packages
        uses: actions/cache@v3
        with:
          path: ~/.m2
          key: ${{ runner.os }}-m2-${{ hashFiles('**/pom.xml') }}
          restore-keys: ${{ runner.os }}-m2

      - name: Collect initial system metrics
        run: |
          set -eo pipefail
          
          # Enregistrer le temps de début
          date +%s%N > metrics/pipeline_start_time.txt
          
          # Collecter les métriques initiales
          echo "=== Initial System Resources ===" > metrics/system/initial_metrics.txt
          top -b -n 1 >> metrics/system/initial_metrics.txt
          
          echo "=== Initial Memory Usage ===" > metrics/system/initial_memory.txt
          free -m >> metrics/system/initial_memory.txt
          
          echo "=== Initial Disk Usage ===" > metrics/system/initial_disk.txt
          df -h >> metrics/system/initial_disk.txt

      - name: Set up JDK 17
        uses: actions/setup-java@v4
        with:
          java-version: '17'
          distribution: 'adopt'
          cache: maven

      - name: Build with Maven and measure energy
        id: build
        timeout-minutes: 5
        env:
          MAVEN_OPTS: "-Xmx2048m -XX:+TieredCompilation -XX:TieredStopAtLevel=1"
        run: |
          set -eo pipefail
          
          # Ajouter Cargo au PATH
          source "$HOME/.cargo/env"
          
          start_time=$(date +%s%N)
          
          # Collecter les métriques avant build
          free -m > metrics/system/pre_build_memory.txt
          
          # Monitoring énergétique avec Scaphandre
          sudo python3 energy_monitor.py \
            "./mvnw -B verify -Dmaven.test.skip=true" \
            metrics/power/build_power_metrics.csv
          
          build_status=$?
          end_time=$(date +%s%N)
          
          # Collecter les métriques post-build
          free -m > metrics/system/post_build_memory.txt
          
          # Enregistrer le temps de build
          echo "$((($end_time - $start_time)/1000000))" > metrics/performance/build_time.txt
          
          # Vérifier le contenu du fichier de métriques
          echo "=== Build power metrics content ==="
          cat metrics/power/build_power_metrics.csv
          
          exit $build_status

      - name: Run tests with energy monitoring
        id: test
        if: success()
        timeout-minutes: 5
        run: |
          set -eo pipefail
          
          # Ajouter Cargo au PATH
          source "$HOME/.cargo/env"
          
          start_time=$(date +%s%N)
          
          # Collecter les métriques pré-tests
          free -m > metrics/system/pre_test_memory.txt
          
          # Monitoring énergétique avec Scaphandre
          sudo python3 energy_monitor.py \
            "./mvnw test" \
            metrics/power/test_power_metrics.csv
          
          test_status=$?
          end_time=$(date +%s%N)
          
          # Collecter les métriques post-tests
          free -m > metrics/system/post_test_memory.txt
          
          # Enregistrer le temps des tests
          echo "$((($end_time - $start_time)/1000000))" > metrics/performance/test_time.txt
          
          # Vérifier le contenu du fichier de métriques
          echo "=== Test power metrics content ==="
          cat metrics/power/test_power_metrics.csv
          
          exit $test_status

      - name: Build Docker image with energy monitoring
        id: docker-build
        if: success()
        timeout-minutes: 5
        run: |
          set -eo pipefail
          
          # Ajouter Cargo au PATH
          source "$HOME/.cargo/env"
          
          start_time=$(date +%s%N)
          
          # Collecter les métriques pré-docker
          free -m > metrics/system/pre_docker_memory.txt
          df -h > metrics/system/pre_docker_disk.txt
          
          # Monitoring énergétique avec Scaphandre
          sudo python3 energy_monitor.py \
            "docker build -t app:latest -f .devcontainer/Dockerfile ." \
            metrics/power/docker_build_power_metrics.csv
          
          build_status=$?
          end_time=$(date +%s%N)
          
          # Collecter les métriques post-docker
          free -m > metrics/system/post_docker_memory.txt
          df -h > metrics/system/post_docker_disk.txt
          
          # Enregistrer le temps de build Docker
          echo "$((($end_time - $start_time)/1000000))" > metrics/performance/docker_time.txt
          
          # Collecter la taille de l'image
          docker images app:latest --format "{{.Size}}" > metrics/performance/docker_image_size.txt
          
          # Vérifier le contenu du fichier de métriques
          echo "=== Docker build power metrics content ==="
          cat metrics/power/docker_build_power_metrics.csv
          
          exit $build_status

      - name: Collect final system metrics
        if: always()
        run: |
          set -eo pipefail

          # Collecter les métriques système finales
          echo "=== Final System Resources ===" > metrics/system/final_metrics.txt
          top -b -n 1 >> metrics/system/final_metrics.txt || echo "Failed to collect top metrics"

          echo "=== Final Memory Usage ===" > metrics/system/final_memory.txt
          free -m >> metrics/system/final_memory.txt || echo "Failed to collect memory metrics"

          echo "=== Final Disk Usage ===" > metrics/system/final_disk.txt
          df -h >> metrics/system/final_disk.txt || echo "Failed to collect disk metrics"

          # Marquer la fin du pipeline
          date +%s%N > metrics/pipeline_end_time.txt

      - name: Verify metrics collection
        if: always()
        run: |
          echo "=== Checking power metrics files ==="
          for file in metrics/power/*.csv; do
            echo "=== Content of $file: ==="
            cat "$file"
            echo "Size of $file: $(wc -l < "$file") lines"
            echo "File permissions: $(ls -l "$file")"
          done

          echo "=== Checking system metrics files ==="
          for file in metrics/system/*; do
            echo "=== Content of $file: ==="
            cat "$file"
          done

          echo "=== Checking performance metrics files ==="
          for file in metrics/performance/*; do
            echo "=== Content of $file: ==="
            cat "$file"
          done

      - name: Save metrics
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: pipeline-metrics
          path: metrics/
          retention-days: 90
          if-no-files-found: warn

      - name: Cleanup
        if: always()
        run: |
          docker system prune -af
