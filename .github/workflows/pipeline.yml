name: Enhanced Java Application Pipeline with Metrics and Energy Monitoring

on:
  push:
    branches: [ pipeline-optimization ]
  pull_request:
    branches: [ pipeline-optimization ]

jobs:
  build-with-metrics:
    runs-on: ubuntu-latest
    timeout-minutes: 60

    services:
      prometheus:
        image: prom/prometheus:latest
        ports:
          - 9090:9090
        options: >-
          --health-cmd "wget -q -O- http://localhost:9090/-/healthy || exit 1"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 3

      pushgateway:
        image: prom/pushgateway:latest
        ports:
          - 9091:9091
        options: >-
          --health-cmd "wget -q -O- http://localhost:9091/-/healthy || exit 1"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 3

    steps:
      - uses: actions/checkout@v4

      - name: Setup directories and tools
        run: |
          set -eo pipefail
          
          # Créer la structure des répertoires
          mkdir -p metrics/system
          mkdir -p metrics/power
          mkdir -p metrics/performance
          
          # Installation des packages nécessaires
          sudo apt-get update
          sudo apt-get install -y linux-tools-common linux-tools-generic python3-pip python3-psutil
          
          # Installation de PowerAPI et dépendances
          pip3 install powerapi==0.9.0 pandas numpy
          sudo powerapi --formula rapl

      - name: Cache Maven packages
        uses: actions/cache@v3
        with:
          path: ~/.m2
          key: ${{ runner.os }}-m2-${{ hashFiles('**/pom.xml') }}
          restore-keys: ${{ runner.os }}-m2

      - name: Start PowerAPI monitoring
        id: start-powerapi
        run: |
          # Démarrer le daemon PowerAPI
          sudo powerapi daemon start --formula rapl
          echo "POWERAPI_PID=$(pgrep -f powerapi)" >> $GITHUB_ENV

      - name: Start monitoring
        id: start-monitoring
        run: |
          set -eo pipefail
          
          # Enregistrer le temps de début
          date +%s%N > metrics/pipeline_start_time.txt
          
          # Collecter les métriques initiales
          echo "=== Initial System Resources ===" > metrics/system/initial_metrics.txt
          top -b -n 1 >> metrics/system/initial_metrics.txt
          
          echo "=== Initial Memory Usage ===" > metrics/system/initial_memory.txt
          free -m >> metrics/system/initial_memory.txt
          
          echo "=== Initial Disk Usage ===" > metrics/system/initial_disk.txt
          df -h >> metrics/system/initial_disk.txt

      - name: Set up JDK 17
        uses: actions/setup-java@v4
        with:
          java-version: '17'
          distribution: 'adopt'
          cache: maven

      - name: Build with Maven
        id: build
        timeout-minutes: 15
        env:
          MAVEN_OPTS: "-Xmx2048m -XX:+TieredCompilation -XX:TieredStopAtLevel=1"
        run: |
          set -eo pipefail
          
          start_time=$(date +%s%N)
          
          # Démarrer la mesure PowerAPI
          sudo powerapi monitor record --formula rapl --pid $$ --output metrics/power/build_power.csv &
          POWER_MONITOR_PID=$!
          
          # Collecter les métriques avant build
          free -m > metrics/system/pre_build_memory.txt
          
          # Build optimisé
          ./mvnw -B verify \
            -Dmaven.test.skip=true \
            -Dcheckstyle.skip=true \
            -T 1C
          
          build_status=$?
          end_time=$(date +%s%N)
          
          # Arrêter la mesure PowerAPI
          kill $POWER_MONITOR_PID
          
          # Collecter les métriques post-build
          free -m > metrics/system/post_build_memory.txt
          
          # Enregistrer le temps de build
          echo "BUILD_TIME=$((($end_time - $start_time)/1000000))" >> $GITHUB_ENV
          echo "$((($end_time - $start_time)/1000000))" > metrics/performance/build_time.txt
          
          exit $build_status

      - name: Run tests
        id: test
        if: success()
        timeout-minutes: 20
        run: |
          set -eo pipefail
          
          start_time=$(date +%s%N)
          
          # Démarrer la mesure PowerAPI
          sudo powerapi monitor record --formula rapl --pid $$ --output metrics/power/test_power.csv &
          POWER_MONITOR_PID=$!
          
          # Collecter les métriques pré-tests
          free -m > metrics/system/pre_test_memory.txt
          
          # Tests optimisés
          ./mvnw test -T 1C
          
          test_status=$?
          end_time=$(date +%s%N)
          
          # Arrêter la mesure PowerAPI
          kill $POWER_MONITOR_PID
          
          # Collecter les métriques post-tests
          free -m > metrics/system/post_test_memory.txt
          
          # Enregistrer le temps des tests
          echo "TEST_TIME=$((($end_time - $start_time)/1000000))" >> $GITHUB_ENV
          echo "$((($end_time - $start_time)/1000000))" > metrics/performance/test_time.txt
          
          exit $test_status

      - name: Build Docker image
        id: docker-build
        if: success()
        timeout-minutes: 10
        run: |
          set -eo pipefail
          
          start_time=$(date +%s%N)
          
          # Démarrer la mesure PowerAPI
          sudo powerapi monitor record --formula rapl --pid $$ --output metrics/power/docker_power.csv &
          POWER_MONITOR_PID=$!
          
          # Collecter les métriques pré-docker
          free -m > metrics/system/pre_docker_memory.txt
          df -h > metrics/system/pre_docker_disk.txt
          
          # Build Docker optimisé
          docker build -t app:latest -f .devcontainer/Dockerfile . --no-cache
          
          build_status=$?
          end_time=$(date +%s%N)
          
          # Arrêter la mesure PowerAPI
          kill $POWER_MONITOR_PID
          
          # Collecter les métriques post-docker
          free -m > metrics/system/post_docker_memory.txt
          df -h > metrics/system/post_docker_disk.txt
          
          # Enregistrer le temps de build Docker
          echo "DOCKER_BUILD_TIME=$((($end_time - $start_time)/1000000))" >> $GITHUB_ENV
          echo "$((($end_time - $start_time)/1000000))" > metrics/performance/docker_time.txt
          
          # Collecter la taille de l'image
          docker images app:latest --format "{{.Size}}" > metrics/performance/docker_image_size.txt
          
          exit $build_status

      - name: Collect and analyze metrics
        if: always()
        run: |
          set -eo pipefail
          
          # Collecter les métriques système finales
          echo "=== Final System Resources ===" > metrics/system/final_metrics.txt
          top -b -n 1 >> metrics/system/final_metrics.txt
          
          echo "=== Final Memory Usage ===" > metrics/system/final_memory.txt
          free -m >> metrics/system/final_memory.txt
          
          echo "=== Final Disk Usage ===" > metrics/system/final_disk.txt
          df -h >> metrics/system/final_disk.txt
          
          # Marquer la fin du pipeline
          date +%s%N > metrics/pipeline_end_time.txt
          
          python3 << EOF
          import pandas as pd
          import glob
          import os

          def analyze_power_metrics():
              power_files = glob.glob('metrics/power/*.csv')
              if not power_files:
                  print("No power metrics found")
                  return
          
              power_data = []
              for file in power_files:
                  stage = os.path.basename(file).replace('_power.csv', '')
                  try:
                      df = pd.read_csv(file)
                      stats = {
                          'stage': stage,
                          'avg_power': df['power'].mean(),
                          'max_power': df['power'].max(),
                          'total_energy': df['power'].sum() * df['power'].count() * 0.1,
                          'duration': len(df) * 0.1
                      }
                      power_data.append(stats)
                  except Exception as e:
                      print(f"Error processing {file}: {e}")
          
              if power_data:
                  power_df = pd.DataFrame(power_data)
                  power_df.to_csv('metrics/power/power_analysis.csv', index=False)
          
                  with open('metrics/power/power_summary.txt', 'w') as f:
                      f.write("Energy Consumption Summary\n")
                      f.write("=========================\n\n")
          
                      for _, row in power_df.iterrows():
                          f.write(f"Stage: {row['stage']}\n")
                          f.write(f"Average Power: {row['avg_power']:.2f} W\n")
                          f.write(f"Maximum Power: {row['max_power']:.2f} W\n")
                          f.write(f"Total Energy: {row['total_energy']:.2f} J\n")
                          f.write(f"Duration: {row['duration']:.2f} s\n\n")

          def analyze_times():
              times = {
                  'build': float(open('metrics/performance/build_time.txt').read().strip()),
                  'test': float(open('metrics/performance/test_time.txt').read().strip()),
                  'docker': float(open('metrics/performance/docker_time.txt').read().strip())
              }
          
              total_time = sum(times.values())
          
              with open('metrics/performance/summary.txt', 'w') as f:
                  f.write("Pipeline Performance Summary\n")
                  f.write("==========================\n\n")
          
                  for stage, duration in times.items():
                      percentage = (duration / total_time * 100)
                      f.write(f"{stage.capitalize()} Stage:\n")
                      f.write(f"Duration: {duration/1000:.2f} seconds\n")
                      f.write(f"Percentage of total time: {percentage:.1f}%\n\n")
          
                  f.write(f"Total Pipeline Duration: {total_time/1000:.2f} seconds\n")
          
              pd.DataFrame([times]).to_csv('metrics/performance/times.csv', index=False)
          
          analyze_power_metrics()
          analyze_times()
          EOF

      - name: Export metrics to Prometheus
        if: always()
        timeout-minutes: 5
        run: |
          set -eo pipefail
          
          function export_metric() {
            local metric_name=$1
            local metric_value=$2
            local stage=$3
          
            if [ -n "$metric_value" ]; then
              echo "${metric_name}{stage=\"${stage}\",project=\"java-app\"} ${metric_value}" | \
                curl --retry 3 --max-time 10 --silent --show-error \
                  --data-binary @- http://localhost:9091/metrics/job/pipeline-metrics || \
                echo "Failed to export metric ${metric_name}"
            fi
          }
          
          # Exporter les temps d'exécution
          export_metric "pipeline_duration_ms" "${BUILD_TIME}" "build"
          export_metric "pipeline_duration_ms" "${TEST_TIME}" "test"
          export_metric "pipeline_duration_ms" "${DOCKER_BUILD_TIME}" "docker"
          
          # Exporter l'utilisation mémoire finale
          mem_usage=$(free -b | grep Mem: | awk '{print $3}')
          export_metric "memory_usage_bytes" "$mem_usage" "final"

      - name: Save metrics
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: pipeline-metrics
          path: metrics/
          retention-days: 90
          if-no-files-found: warn

      - name: Cleanup
        if: always()
        run: |
          # Arrêter PowerAPI
          if [ -n "$POWERAPI_PID" ]; then
            sudo powerapi daemon stop
          fi
          
          docker system prune -af
          rm -rf node_exporter*
